# SystÃ¨me ASR Robuste : Ã‰valuation de Wav2Vec 2.0 et ModÃ¨les de Langage N-gram

## ğŸ¯ Objectif du Projet

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du **Master 2 IAÂ²VR (Intelligence Artificielle et ses Applications en Vision et Robotique)** Ã  l'UniversitÃ© de Lorraine. L'objectif est d'Ã©valuer la robustesse et les performances d'un systÃ¨me de reconnaissance automatique de la parole (ASR) de pointe face Ã  des contraintes acoustiques et linguistiques rÃ©elles.

Le pipeline analyse le modÃ¨le **Wav2Vec 2.0 (Base-960h)** de Facebook (Meta AI) selon trois axes critiques :

1. **Robustesse acoustique** : Impact de la dÃ©gradation du signal (bruit blanc) avec des niveaux de SNR (Signal-to-Noise Ratio) allant de 5dB Ã  35dB.
2. **VariabilitÃ© des locuteurs** : Comparaison des performances sur des profils vocaux hÃ©tÃ©rogÃ¨nes (hommes, femmes, enfants).
3. **Correction sÃ©mantique** : Quantification du gain de prÃ©cision (rÃ©duction du Word Error Rate) apportÃ© par l'intÃ©gration d'un **ModÃ¨le de Langage N-gram** via un dÃ©codage par Beam Search.

## ğŸ“‚ Structure du Projet

L'organisation logicielle est modulaire pour garantir une sÃ©paration claire des responsabilitÃ©s et une portabilitÃ© maximale entre diffÃ©rents environnements de calcul.

```text
projet-cpm/
â”œâ”€â”€ main.py              # Script principal (Chef d'orchestre du pipeline)
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python (Torchaudio, Pyctcdecode, etc.)
â”œâ”€â”€ .gitignore           # Exclusion des environnements, donnÃ©es lourdes et caches
â”œâ”€â”€ results_stats.csv    # RÃ©sultats consolidÃ©s (Moyennes WER et Intervalles de Confiance)
â”œâ”€â”€ results_detailed.csv # Base de donnÃ©es complÃ¨te des 2800 transcriptions brutes
â”œâ”€â”€ plots/               # Visualisations scientifiques gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ graph1_snr_ci.png    # Impact du niveau de bruit
â”‚   â”œâ”€â”€ graph2_speaker_ci.png # Performance par type de locuteur
â”‚   â””â”€â”€ graph3_length_ci.png  # Influence de la longueur des sÃ©quences
â”œâ”€â”€ src/                 # CÅ“ur logique du systÃ¨me
â”‚   â”œâ”€â”€ __init__.py      
â”‚   â”œâ”€â”€ config.py        # Gestion du GPU, des chemins et hyperparamÃ¨tres
â”‚   â”œâ”€â”€ audio_utils.py   # Chargement audio portable (Soundfile/TorchAudio hybride)
â”‚   â”œâ”€â”€ model_loader.py  # Chargement Wav2Vec2 et dÃ©codeur KenLM
â”‚   â”œâ”€â”€ inference.py     # Algorithmes de transcription (Greedy vs Beam Search)
â”‚   â””â”€â”€ evaluation.py    # MÃ©triques (WER) et Bootstrap statistique (IC 95%)
â”œâ”€â”€ logs/                # Journaux d'exÃ©cution (Suivi des performances GPU et erreurs)
â””â”€â”€ data/                # [IGNORÃ‰ PAR GIT] Corpus audio et ModÃ¨le de Langage (.arpa)
```

## ğŸ“Š MÃ©thodologie Scientifique

### Ã‰valuation du Taux d'Erreur (WER)

Pour chaque Ã©chantillon audio, le systÃ¨me produit et Ã©value deux types de transcriptions :

- **WER Greedy** : Performance brute du modÃ¨le acoustique (dÃ©cisions locales par frame).
- **WER with LM** : Performance aprÃ¨s intÃ©gration des probabilitÃ©s linguistiques du modÃ¨le de langage N-gram.

### Analyse Statistique (Bootstrap)

Afin de garantir la validitÃ© scientifique des conclusions, nous appliquons la mÃ©thode du Bootstrap :

- **Intervalles de Confiance (IC 95%)** : CalculÃ©s sur 1000 itÃ©rations de rÃ©-Ã©chantillonnage pour chaque mÃ©trique.

Cette approche permet de confirmer statistiquement que les Ã©carts de performance observÃ©s ne sont pas dus Ã  la variance de l'Ã©chantillon mais bien aux caractÃ©ristiques intrinsÃ¨ques du modÃ¨le et des donnÃ©es.

## ğŸš€ Guide de DÃ©marrage

### PrÃ©requis

Le projet a Ã©tÃ© dÃ©veloppÃ© et optimisÃ© sur une instance Google Cloud Compute Engine Ã©quipÃ©e d'un GPU NVIDIA L4. Pour assurer la reproductibilitÃ© sur n'importe quel OS (Linux, Windows, macOS), la lecture audio est gÃ©rÃ©e via soundfile, Ã©liminant les dÃ©pendances complexes liÃ©es aux codecs systÃ¨me (FFmpeg).

### Installation

```bash
# CrÃ©ation et activation de l'environnement virtuel
python3 -m venv asr_env
source asr_env/bin/activate

# Installation des dÃ©pendances (sans cache pour optimiser l'espace disque)
pip install --no-cache-dir -r requirements.txt
```

### ExÃ©cution

Pour traiter l'intÃ©gralitÃ© du corpus (2800 fichiers), calculer les mÃ©triques et gÃ©nÃ©rer les graphiques d'analyse :

```bash
python main.py
```

## ğŸ“ˆ RÃ©sultats et Analyse

Les graphiques gÃ©nÃ©rÃ©s dans le dossier `/plots` mettent en Ã©vidence la corrÃ©lation inverse entre le SNR et le WER. L'apport du modÃ¨le de langage est particuliÃ¨rement significatif dans les zones de bruit modÃ©rÃ©, oÃ¹ les contraintes linguistiques permettent de lever les ambiguÃ¯tÃ©s phonÃ©tiques que le modÃ¨le acoustique seul ne peut rÃ©soudre.

## ğŸ‘¤ Auteurs

- **El Hadji Dame Lo Kaba** - Ã‰tudiant Master 2 IAÂ²VR, UniversitÃ© de Lorraine
- **Salim Fourati** - Ã‰tudiant Master 2 IAÂ²VR, UniversitÃ© de Lorraine

---

## ğŸ“ License

Ce projet a Ã©tÃ© rÃ©alisÃ© dans un cadre acadÃ©mique Ã  l'UniversitÃ© de Lorraine.
